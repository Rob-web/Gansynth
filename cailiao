#建立球形插值
def slerp(p0, p1, t):

  omega = np.arccos(np.dot(
      np.squeeze(p0/np.linalg.norm(p0)), np.squeeze(p1/np.linalg.norm(p1))))
  so = np.sin(omega)
  return np.sin((1.0-t)*omega) / so * p0 + np.sin(t*omega)/so * p1




def load_midi(midi_path, min_pitch=36, max_pitch=84):   

 # 引入midi文件，并将其转换为一个序列音符notesequence，notes表示每一个音符，其中每个音符包含4个表示
  midi_path = util.expand_path(midi_path)
  ns = note_seq.midi_file_to_sequence_proto(midi_path)
  pitches = np.array([n.pitch for n in ns.notes])
  velocities = np.array([n.velocity for n in ns.notes])
  start_times = np.array([n.start_time for n in ns.notes])
  end_times = np.array([n.end_time for n in ns.notes])
  valid = np.logical_and(pitches >= min_pitch, pitches <= max_pitch)     # 逻辑与门
  notes = {'pitches': pitches[valid],
           'velocities': velocities[valid],
           'start_times': start_times[valid],
           'end_times': end_times[valid]}
  return ns, notes

# 将音频片段clip输出成wave格式
def save_wav(audio, fname, sr=16000):
  wavfile.write(fname, sr, audio.astype('float32'))
  print('Saved to {}'.format(fname))


def main(unused_argv):
  absl.flags.FLAGS.alsologtostderr = True

  # Load the model
  flags = lib_flags.Flags({'batch_size_schedule': [FLAGS.batch_size]})   
  model = lib_model.Model.load_from_path(FLAGS.ckpt_dir, flags)   # 载入训练好的模型

  # Make an output directory if it doesn't exist    #制造一个输出音频的路径
  output_dir = util.expand_path(FLAGS.output_dir)            
  if not tf.gfile.Exists(output_dir):
    tf.gfile.MakeDirs(output_dir)

  if FLAGS.midi_file:
    # If a MIDI file is provided, synthesize interpolations across the clip
    # 如果有midi文件，那么音符将与潜向量进行插值合成
    
    unused_ns, notes = gu.load_midi(FLAGS.midi_file)      # load_midi函数：引入midi文件，并将其转换为音符notes     

    # Distribute latent vectors linearly in time
    z_instruments, t_instruments = gu.get_random_instruments(      # get_random_instruments函数：得到时间上均匀分布的随机潜在向量
        model,
        notes['end_times'][-1],
        secs_per_instrument=FLAGS.secs_per_instrument)

    # Get latent vectors for each note                           # 得到midi文件中每个音符所对应的潜向量，称为 z_notes
    z_notes = gu.get_z_notes(notes['start_times'], z_instruments, t_instruments)

    # Generate audio for each note                   # 由midi音符和潜向量创造出音频 audio_notes
    print('Generating {} samples...'.format(len(z_notes)))
    audio_notes = model.generate_samples_from_z(z_notes, notes['pitches'])

    # Make a single audio clip                        # 在音频 audio_notes 中取一个片段 clip
    audio_clip = gu.combine_notes(audio_notes,
                                  notes['start_times'],
                                  notes['end_times'],
                                  notes['velocities'])

    # Write the wave files          # 把片段 clip 转换为wave格式进行保存在文件中
    fname = os.path.join(output_dir, 'generated_clip.wav')    
    gu.save_wav(audio_clip, fname)
  else:
    # Otherwise, just generate a batch of random sounds     
    #如果没有midi文件，就直接使用潜向量生成音符
    # 该generate_samples函数最终返回的是generate_samples_from_z（），即generate_samples函数生成的是音频 
    waves = model.generate_samples(FLAGS.batch_size)              
    # Write the wave files        # 把音频waves 转换为wave格式进行保存在文件中
    for i in range(len(waves)):
      fname = os.path.join(output_dir, 'generated_{}.wav'.format(i))  #
      gu.save_wav(waves[i], fname)


def waves_to_stfts(self, waves):
    """将wave转换为stft短时傅里叶形式

    """
    waves_padded = tf.pad(waves, [[0, 0], [self._pad_l, self._pad_r], [0, 0]])
    stfts = tf.signal.stft(
        waves_padded[:, :, 0],
        frame_length=self._nfft,
        frame_step=self._nhop,
        fft_length=self._nfft,
        pad_end=False)[:, :, :, tf.newaxis]
    stfts = stfts[:, :, 1:] if self._discard_dc else stfts[:, :, :-1]
    stft_shape = stfts.get_shape().as_list()[1:3]
    if tuple(stft_shape) != tuple(self._spec_shape):
      raise ValueError(
          'Spectrogram returned the wrong shape {}, is not the same as the '
          'constructor spec_shape {}.'.format(stft_shape, self._spec_shape))
    return stfts
    
    
def stfts_to_waves(self, stfts):
    """将stft短时傅里叶形式转换为wave
 
    """
    dc = 1 if self._discard_dc else 0
    nyq = 1 - dc
    stfts = tf.pad(stfts, [[0, 0], [0, 0], [dc, nyq], [0, 0]])
    waves_resyn = tf.signal.inverse_stft(
        stfts=stfts[:, :, :, 0],
        frame_length=self._nfft,
        frame_step=self._nhop,
        fft_length=self._nfft,
        window_fn=tf.signal.inverse_stft_window_fn(
            frame_step=self._nhop))[:, :, tf.newaxis]
    # Python does not allow rslice of -0
    if self._pad_r == 0:
      return waves_resyn[:, self._pad_l:]
    else:
      return waves_resyn[:, self._pad_l:-self._pad_r]
      
      
def stfts_to_specgrams(self, stfts):
    """将stft短时傅里叶形式转换为声谱图形式

    """
    stfts = stfts[:, :, :, 0]

    logmag = self._safe_log(tf.abs(stfts))

    phase_angle = tf.angle(stfts)
    if self._ifreq:
      p = spectral_ops.instantaneous_frequency(phase_angle)
    else:
      p = phase_angle / np.pi

    return tf.concat(
        [logmag[:, :, :, tf.newaxis], p[:, :, :, tf.newaxis]], axis=-1)
        
        
def specgrams_to_stfts(self, specgrams):
    """将声谱图形式转换为短时傅里叶形式

    """
    logmag = specgrams[:, :, :, 0]
    p = specgrams[:, :, :, 1]

    mag = tf.exp(logmag)

    if self._ifreq:
      phase_angle = tf.cumsum(p * np.pi, axis=-2)
    else:
      phase_angle = p * np.pi

    return spectral_ops.polar2rect(mag, phase_angle)[:, :, :, tf.newaxis]
    
    
    
def specgrams_to_melspecgrams(self, specgrams):
    """将声谱图转换为梅尔频谱

    """
    if self._mel_downscale is None:
      return specgrams

    logmag = specgrams[:, :, :, 0]
    p = specgrams[:, :, :, 1]

    mag2 = tf.exp(2.0 * logmag)
    phase_angle = tf.cumsum(p * np.pi, axis=-2)

    l2mel = tf.to_float(self._linear_to_mel_matrix())
    logmelmag2 = self._safe_log(tf.tensordot(mag2, l2mel, 1))
    mel_phase_angle = tf.tensordot(phase_angle, l2mel, 1)
    mel_p = spectral_ops.instantaneous_frequency(mel_phase_angle)

    return tf.concat(
        [logmelmag2[:, :, :, tf.newaxis], mel_p[:, :, :, tf.newaxis]], axis=-1)
        
        
        
  def melspecgrams_to_specgrams(self, melspecgrams):
    """将梅尔频谱转换成声谱图

    """
    if self._mel_downscale is None:
      return melspecgrams

    logmelmag2 = melspecgrams[:, :, :, 0]
    mel_p = melspecgrams[:, :, :, 1]

    mel2l = tf.to_float(self._mel_to_linear_matrix())
    mag2 = tf.tensordot(tf.exp(logmelmag2), mel2l, 1)
    logmag = 0.5 * self._safe_log(mag2)
    mel_phase_angle = tf.cumsum(mel_p * np.pi, axis=-2)
    phase_angle = tf.tensordot(mel_phase_angle, mel2l, 1)
    p = spectral_ops.instantaneous_frequency(phase_angle)

    return tf.concat(
        [logmag[:, :, :, tf.newaxis], p[:, :, :, tf.newaxis]], axis=-1)


def provide_data(self, batch_size):
    """返回一个批次的data和对应的label，即real_images, real_one_hot_labels = (audio, labels)。这里的数据是nsynth数据集，即真实的数据集"""
    with tf.name_scope('inputs'):
      with tf.device('/cpu:0'):
        dataset = self.dataset.provide_dataset()
        dataset = dataset.shuffle(buffer_size=1000)
        dataset = dataset.map(self._map_fn, num_parallel_calls=4)
        dataset = dataset.batch(batch_size)
        dataset = dataset.prefetch(1)

        iterator = dataset.make_initializable_iterator()
        tf.add_to_collection(tf.GraphKeys.TABLE_INITIALIZERS,
                             iterator.initializer)

        data, one_hot_labels = iterator.get_next()
        data.set_shape([batch_size, None, None, None])
        one_hot_labels.set_shape([batch_size, None])
        return data, one_hot_labels
        
def provide_one_hot_labels(self, batch_size):
    """返回gen的one_hot_label."""
    pitch_counts = self.get_pitch_counts()
    pitches = sorted(pitch_counts.keys())
    counts = [pitch_counts[p] for p in pitches]
    indices = tf.reshape(
        tf.multinomial(tf.log([tf.to_float(counts)]), batch_size), [batch_size])
    one_hot_labels = tf.one_hot(indices, depth=len(pitches))
    return one_hot_labels
    
    
def get_stage_ids(**kwargs):
  """Returns a list of stage ids.
  Args:
    **kwargs: A dictionary of
        'train_root_dir': A string of root directory of training logs.
        'num_resolutions': An integer of number of progressive resolutions.
  """
  train_sub_dirs = [
      sub_dir for sub_dir in tf.gfile.ListDirectory(kwargs['train_root_dir'])
      if sub_dir.startswith('stage_')
  ]

  # If fresh start, start with start_stage_id = 0
  # If has been trained for n = len(train_sub_dirs) stages, start with the last
  # stage, i.e. start_stage_id = n - 1.
  start_stage_id = max(0, len(train_sub_dirs) - 1)

  return list(range(start_stage_id, get_total_num_stages(**kwargs)))
  
  
  
  
def get_stage_ids(**kwargs):
  """得到一个list的stage
  """
  train_sub_dirs = [
      sub_dir for sub_dir in tf.gfile.ListDirectory(kwargs['train_root_dir'])
      if sub_dir.startswith('stage_')
  ]

  # If fresh start, start with start_stage_id = 0
  # If has been trained for n = len(train_sub_dirs) stages, start with the last
  # stage, i.e. start_stage_id = n - 1.
  start_stage_id = max(0, len(train_sub_dirs) - 1)

  return list(range(start_stage_id, get_total_num_stages(**kwargs)))
  
  
  
def get_batch_size(stage_id, **kwargs):
  """得到每个stage中的batch size值
  我们希望batch_size的长度 == 分辨率的大小，因此每一个stage对应着一个分辨率也就是对应着一个batch size
  """
  batch_size_schedule = kwargs['batch_size_schedule']
  num_resolutions = kwargs['num_resolutions']
  if len(batch_size_schedule) < num_resolutions:
    batch_size_schedule = (
        [batch_size_schedule[0]] * (num_resolutions - len(batch_size_schedule))
        + batch_size_schedule)

  return int(batch_size_schedule[(stage_id + 1) // 2])


def train(model, **kwargs):
  """训练第stage_id个progressive GAN

  """
  logging.info('stage_id=%d, num_blocks=%d, num_images=%d', model.stage_id,
               model.num_blocks, model.num_images)

  scaffold = make_scaffold(model.stage_id, model.optimizer_var_list, **kwargs)

  logdir = make_train_sub_dir(model.stage_id, **kwargs)
  print('starting training, logdir: {}'.format(logdir))
  hooks = []
  if model.stage_train_time_limit is None:
    hooks.append(tf.train.StopAtStepHook(last_step=model.num_images))
  hooks.append(tf.train.LoggingTensorHook(
      [make_status_message(model)], every_n_iter=1))
  hooks.append(TrainTimeHook(model.train_time, model.stage_train_time_limit))
  if kwargs['debug_hook']:
    hooks.append(ProganDebugHook())
  tfgan.gan_train(
      model.gan_train_ops,
      logdir=logdir,
      get_hooks_fn=tfgan.get_sequential_train_hooks(tfgan.GANTrainSteps(1, 1)),
      hooks=hooks,
      master=kwargs['master'],
      is_chief=(kwargs['task'] == 0),
      scaffold=scaffold,
      save_checkpoint_secs=600,
      save_summaries_steps=(kwargs['save_summaries_num_images']))

  
def define_train_ops(gan_model, gan_loss, **kwargs):
  """定义progressive GAN的训练优化器.
 
  """
  with tf.variable_scope('progressive_gan_train_ops') as var_scope:
    beta1, beta2 = kwargs['adam_beta1'], kwargs['adam_beta2']
    gen_opt = tf.train.AdamOptimizer(kwargs['generator_learning_rate'], beta1,
                                     beta2)
    dis_opt = tf.train.AdamOptimizer(kwargs['discriminator_learning_rate'],
                                     beta1, beta2)
    gan_train_ops = tfgan.gan_train_ops(gan_model, gan_loss, gen_opt, dis_opt)
  return gan_train_ops, tf.get_collection(
      tf.GraphKeys.GLOBAL_VARIABLES, scope=var_scope.name)
